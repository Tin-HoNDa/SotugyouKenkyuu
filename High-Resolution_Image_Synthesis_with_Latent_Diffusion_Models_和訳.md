# High-Resolutional Image Synthesis with Latent Diffusion Models

## 概要

拡散モデル（DM）は、画像形成プロセスをノイズ除去オートエンコーダの逐次適用に分解することで、画像データおよびそれ以外のデータに対して最先端の合成結果を実現する。また、その定式化により、再学習することなく画像生成プロセスを制御するためのガイド機構を実現することができる。しかし、これらのモデルは通常ピクセル空間で直接動作するため、強力なDMの最適化はしばしば数百GPU日を消費し、推論は逐次評価により高価となる。DMの品質と柔軟性を維持しつつ、限られた計算資源でDMの学習を可能にするために、我々は、強力な事前学習済みオートエンコーダの潜在空間にDMを適用する。従来の研究とは異なり、このような表現で拡散モデルを学習することで、初めて複雑さの軽減と細部の保存の間の最適に近い点に到達し、視覚的忠実度を大幅に向上させることができる。また、クロスアテンションレイヤーをモデルアーキテクチャに導入することで、拡散モデルをテキストやバウンディングボックスのような一般的な条件入力に対する強力で柔軟なジェネレーターに変え、畳み込み方式で高解像度合成を可能にする。我々の潜在拡散モデル（LDM）は、ピクセルベースのDMと比較して計算量を大幅に削減しながら、画像インペインティングとクラス条件付き画像合成で新たな最先端スコアを達成し、テキストから画像合成、無条件画像生成、超解像を含む様々なタスクで高い競争力を発揮する。

## 1 はじめに

![より積極的でないダウンサンプリングによる達成可能な品質の上限の後押し](2023-06-02-11-27-54.png)
図1：**より積極的でないダウンサンプリングによる達成可能な品質の上限の後押し**
拡散モデルは空間データに対して優れた帰納的バイアスを提供するため、潜在空間における関連する生成モデルの重い空間ダウンサンプリングは必要ないが、適切な自動符号化モデルによってデータの次元を大幅に削減できる（第3節参照）。画像はDIV2K[^1]の検証セットで、$512^2$ pxで評価した。再構成FIDs [^29]とPSNRはImageNet-val[^12]で計算したもの。（表8参照）

画像合成は、コンピュータビジョン分野の中で最も目覚しい発展を遂げている分野の一つであるが、同時に最も計算量の多い分野の一つでもある。特に複雑で自然なシーンの高解像度合成は、現在、自己回帰（AR）変換器の数十億のパラメータを含む尤度ベースモデルのスケールアップが主流となっている[^66] [^67]。一方、GAN [^3] [^27] [^40]の有望な結果は、その敵対的学習手順が複雑なマルチモーダル分布のモデリングに容易に拡張できないため、ほとんどが比較的に変動性の低いデータに限られていることが明らかにされている。最近では、ノイズ除去オートエンコーダの階層から構築される拡散モデル [^82] が、画像合成 [^30] [^85] 以降 [^7] [^45] [^48] [^57] において印象的な結果を達成し、クラス条件付き画像合成 [^31] や超解像 [^72] の最先端を定義していることが示されている。さらに、他のタイプの生成モデル[^19] [^46] [^69]とは対照的に、無条件DMでさえ、インペインティングやカラー化[^85]、ストロークベースの合成[^53]といったタスクに容易に適用することができる。尤度ベースモデルであるため、GANのようなモード崩壊や学習不安定性がなく、また、パラメータ共有を多用することで、ARモデルのように何十億ものパラメータを必要とせず、自然画像の非常に複雑な分布をモデル化できる [^67] 。

### 高解像度画像合成の民主化

DMは尤度ベースモデルのクラスに属し、そのモードカバー動作により、データの知覚できない詳細をモデル化するために過剰な容量（したがって計算リソース）を費やす傾向がある[^16] [^73]。再重み付け変分目的 [^30] は、最初のノイズ除去ステップをアンダーサンプリングすることでこの問題に対処することを目的としているが、このようなモデルの訓練と評価には、RGB画像の高次元空間における関数評価（および勾配計算）の繰り返しが必要となるため、DMは依然として計算負荷が高い。例えば、最も強力なDMの学習には数百GPU日（例えば[^15]では150～1000V100日）かかることが多く、入力空間のノイズバージョンで繰り返し評価することで推論も高くなるため、5万サンプルを作成するにはA100GPU1台で約5日[^15]かかる。このことは、研究コミュニティや一般ユーザーにとって2つの結果をもたらす。第一に、このようなモデルの学習には、研究分野のごく一部にしか利用できない大規模な計算資源が必要であり、膨大なカーボンフットプリントが残る[^65] [^86]。第二に、すでに訓練されたモデルを評価することは、同じモデルアーキテクチャを多数のステップ（例えば、[^15]では25〜1000ステップ）で連続して実行しなければならないため、時間とメモリにコストがかかる。

この強力なモデルクラスへのアクセス性を高め、同時にその多大な資源消費量を削減するためには、学習とサンプリングの両方の計算量を削減する方法が必要である。したがって、DMの性能を損なわずに計算量を減らすことは、DMの利用しやすさを向上させる鍵となる。

### 潜在空間への旅立ち

私たちのアプローチは、画素空間ですでに訓練された拡散モデルの分析から始まる。図2は、学習済みモデルのレートとディストーションのトレードオフを示したものである。他の尤度ベースモデルと同様に、学習は大きく2つの段階に分けられる。第一段階は知覚的圧縮で、高周波の細部を除去するが、意味的な変化はほとんど学習されない。第二段階では、実際の生成モデルがデータの意味的・概念的な構成要素を学習する（意味的圧縮）。このように、我々はまず、高解像度画像合成のための拡散モデルを訓練するために、知覚的に同等であるが計算上より適した空間を見つけることを目的としている。

![知覚的圧縮と意味的圧縮の図解](2023-06-02-11-45-51.png)
図2：**知覚的圧縮と意味的圧縮の図解**
デジタル画像のほとんどのビットは、知覚できない細部に対応している。DMは、責任損失項を最小化することにより、この意味的に無意味な情報を抑制することができるが、（学習時の）勾配と（学習と推論の）ニューラルネットワークのバックボーンは、依然としてすべてのピクセルで評価する必要があるため、余計な計算と不必要に高価な最適化と推論につながる。
我々は、効果的な生成モデルとして潜在拡散モデル（LDM）を提案し、知覚できない細部のみを除去するマイルドな圧縮段階を別に設ける。データおよび画像は[^30]より引用。

一般的な方法 [^11] [^23] [^66] [^67] [^96] に従って、我々はトレーニングを2つの異なるフェーズに分ける。まず、データ空間と知覚的に等価な低次元の表現空間を提供するオートエンコーダを訓練する。重要なことは、先行研究[^23] [^66]とは対照的に、空間次元に関してより優れたスケーリング特性を示す学習済み潜在空間でDMを訓練するため、過度の空間圧縮に頼る必要がないことである。また、複雑さが軽減されたことで、1回のネットワークパスで潜在空間から効率的に画像を生成することができる。この結果、潜在拡散モデル(LDMs)と呼ばれるモデルクラスが誕生した。

このアプローチの顕著な利点は、普遍的な自動符号化ステージを一度だけ訓練する必要があるため、複数のDM訓練や、おそらく全く異なるタスクの探索のために再利用できることである[^81]。これにより、様々な画像から画像、テキストから画像へのタスクに対して、多数の拡散モデルを効率的に探索することができる。後者については、変換器をDMのUNetバックボーン[^71]に接続し、任意のタイプのトークンベースの条件付け機構を可能にするアーキテクチャを設計する（第3.3節を参照）。

まとめると、我々の仕事は以下のような貢献をしている。

1. 純粋な変換器ベースのアプローチ[^23] [^66]とは対照的に、本手法は高次元のデータに対してより優雅にスケールするため、
   a. 従来よりも忠実で詳細な再構成を提供する圧縮レベルで動作し（図1参照）、
   b. メガピクセル画像の高解像度合成に効率的に適用することが可能である。
2. 我々は、複数のタスク（無条件画像合成、インペインティング、確率的超解像）およびデータセットにおいて、計算コストを大幅に削減しながら、競争力のある性能を達成した。また、ピクセルベースの拡散アプローチと比較して、推論コストを大幅に削減することができる。
3. エンコーダ／デコーダアーキテクチャとスコアベースの事前学習を同時に行う先行研究[^93]とは対照的に、我々のアプローチでは再構成能力と生成能力の微妙な重み付けを必要としないことを示している。これにより、極めて忠実な再構成が保証され、潜在空間の正則化もほとんど必要ない。
4. 超解像、インペインティング、意味合成などの高密度な条件を持つタスクに対して、本モデルを畳み込み方式で適用することで、約$1024^2$pxの大規模で一貫した画像をレンダリングできることを見出した。
5. さらに、クロスアテンションに基づく汎用的な条件付け機構を設計し、マルチモーダルな学習を可能にした。これを用いて、クラス条件付けモデル、テキストから画像への変換モデル、レイアウトから画像への変換モデルを学習する。
6. 最後に、DMの学習以外にも様々なタスクに再利用可能な潜在拡散モデルや自動符号化モデルを[https://github.com/CompVis/latent-diffusion]で事前学習して公開する[^81]。

## 2 関連研究

### 画像合成のための生成モデル

画像の高次元の性質は、生成的なモデリングに明確な課題を与える。Generative Adversarial Networks (GAN) [^27]は、高解像度の画像を効率よくサンプリングすることができ、知覚的な品質も高い[^3] [^42]が、最適化が難しく[^2] [^28] [^54] 、データの分布を完全に把握することに苦労する[^55]。これに対し、尤度ベースの手法は、密度推定を重視するため、最適化がよりうまくいく。変分オートエンコーダ（VAE）[^46]やフローベースモデル[^18] [^19]は、高解像度画像の効率的な合成を可能にするが[^9] [^44] [^92]、サンプル品質はGANと同程度ではない。自己回帰モデル（ARM）[^6] [^10] [^94] [^95]は密度推定で高い性能を発揮するが、計算量の多いアーキテクチャ[^97]と連続したサンプリングプロセスにより、低解像度画像に限定される。画像のピクセルベースの表現には、ほとんど知覚できない高周波の詳細が含まれているため[^16] [^73]、最尤訓練はそのモデル化に不釣り合いな量の容量を費やし、結果として長い訓練時間を要することになる。より高い解像度に対応するため、いくつかの2段階アプローチ [^23] [^67] [^101] [^103] では、ARMを使用して、生のピクセルではなく、圧縮された潜在画像空間をモデル化する。

最近、**拡散確率モデル** (Diffusion Probabilistic Models) [^82]は、密度推定[^45]やサンプル品質[^15]で最先端の結果を達成している。これらのモデルの生成能力は、その基礎となるニューラル・バックボーンが U-Net として実装されている場合に、画像類似データの帰納的バイアスに自然に適合することに起因する[^15] [^30] [^71] [^85]。最良の合成品質は、通常、再重量化された目的語[^30]を学習に使用したときに達成される。この場合、DMは非可逆圧縮機に相当し、画質と圧縮能力を交換することができる。しかし、これらのモデルをピクセル空間で評価・最適化すると、推論速度が遅く、学習コストが非常に高くなるという欠点がある。前者は高度なサンプリング戦略[^47] [^75] [^84]や階層的アプローチ[^31] [^93]によって部分的に対処できるが、高解像度画像データでの学習には常に高価な勾配の計算が必要である。我々は、低次元の圧縮された潜在空間で動作するLDMを提案することで、この2つの欠点に対処する。これにより、計算量が少なくなり、合成の質をほとんど落とさずに推論を高速化することができる（図1参照）。

### 2段階画像合成

個々の生成アプローチの欠点を軽減するために、多くの研究[^11] [^23] [^67] [^70] [^101] [^103]が、2段階のアプローチによって、異なる手法の長所を組み合わせて、より効率的で性能の高いモデルを作ることに取り組んでいる。VQ-VAE[^67] [^101]は、自己回帰モデルを用いて、離散化された潜在空間に対する表現的な事前分布を学習する[^66]。このアプローチをテキスト-画像生成に拡張し、離散化した画像とテキスト表現に対する共同分布を学習する。より一般的には、[^70]は、条件付き反転ネットワークを用いて、多様なドメインの潜在空間間の汎用的な転送を提供している。VQ-VAEとは異なり、VQGAN [^23] [^103]は、自己回帰変換器をより大きな画像に拡大するために、敵対的かつ知覚的な目的を持つ第1段階を採用している。しかし、実現可能なARM学習に必要な高い圧縮率は、何十億もの学習可能なパラメータを導入するため[^23] [^66]、このようなアプローチの全体的な性能を制限し、より少ない圧縮は高い計算コストと引き換えになる[^23] [^66]。我々の提案するLDMは、畳み込みバックボーンにより、高次元の潜在空間に対してより優しくスケールするため、このようなトレードオフを防ぐことができる。したがって、我々は、高忠実度の再構成を保証しながら、生成拡散モデルに知覚的圧縮を任せすぎず、強力な第1段階の学習を最適に仲介する圧縮レベルを自由に選択することができる（図1参照）。

スコアベースの事前学習とともに符号化・復号化モデルを学習するアプローチ[^93]や個別学習するアプローチ[^80]が存在するが、前者は再構成能力と生成能力の間の難しい秤量が必要であり[^11]、我々のアプローチ（第4項）に劣り、後者は人間の顔などの高度な構造の画像に焦点を当てている。

## 3 手法

高解像度画像合成のために拡散モデルを学習する際の計算量を減らすために、拡散モデルは対応する損失項をアンダーサンプリングすることで知覚的に無関係な細部を無視することができるが[^30]、ピクセル空間での高価な関数評価を必要とし、計算時間やエネルギー資源に大きな需要があることを確認した。

我々は、この欠点を回避するために、圧縮学習と生成学習を明示的に分離することを提案する（図2参照）。これを実現するために、画像空間と知覚的に等価な空間を学習する自動符号化モデルを利用し、計算量を大幅に削減する。

このようなアプローチにはいくつかの利点がある。

1. 高次元の画像空間から離れることで、低次元の空間でサンプリングが行われるため、計算効率が非常に高いDMを得ることができる。
2. U-Netアーキテクチャ[^71]に由来するDMの帰納的バイアスを利用することで、空間構造を持つデータに対して特に有効であるため、従来のアプローチ [^23] [^66]で必要とされた、積極的で品質を下げる圧縮レベルの必要性が緩和される。
3. 最後に、潜在空間を複数の生成モデルの学習に利用でき、単一画像CLIPガイド付き合成[^25]などの他の下流アプリケーションに利用できる汎用的な圧縮モデルを得ることができる。

### 3.1 知覚的画像圧縮

我々の知覚圧縮モデルは、以前の研究 [^23] に基づいており、知覚損失 [^106] とパッチベース [^33] 敵対的目的 [^20] [^23] [^103] の組み合わせによって訓練されたオートエンコーダで構成されている。これにより、局所的なリアリズムを強制することで再構成が画像多様体に限定されることを保証し、$L_2$ や $L_1$ 目的などの画素空間損失のみに依存することで生じるぼやけを回避する。

より正確には、RGB空間の画像 $x\in \mathbb{R}^{H\times W\times3}$ が与えられたとき、エンコーダ $\mathcal{E}$ は $x$ を潜在表現 $z=\mathcal{E}(x)$ に符号化し、デコーダ $\mathcal{D}$ は潜在表現から画像を再構成し、$\tilde x=\mathcal{D}(z)=\mathcal{D}(\mathcal{E}(x))\space(z\in \mathbb{R}^{H\times W\times3})$ を与える。重要なのは、エンコーダが画像を係数 $f=H/h=W/w$ でダウンサンプリングすることであり、我々は異なるダウンサンプリング係数 $f=2^m\space(m\in\mathbb{N})$で調査する。

任意に高変量な潜在空間を避けるために、2つの異なる正則化の実験を行った。最初のバリエーションであるKL-reg.は、VAE [^46] [^69]と同様に、学習した潜在能力に対して標準正規形に対するわずかなKL-penaltyを課すが、VQ-reg.はデコーダ内のベクトル量子化層 [^96] を用いる。このモデルはVQGAN [^23]と解釈できるが、量子化層がデコーダに吸収されている。我々の後続のDMは、学習した潜在空間 $z=\mathcal{E}(x)$ の2次元構造を扱うように設計されているため、比較的穏やかな圧縮率を使用し、非常に優れた再構成を達成することができる。これは、学習した空間 $z$ の分布を自己回帰的にモデル化するために、任意の1次元の順序に依存し、それによって $z$ の固有の構造の多くを無視した先行研究 [^23] [^66] とは対照的である。したがって、我々の圧縮モデルは $x$ の詳細をよりよく保存する（表8参照）。目的および学習の詳細については付録を参照。

### 3.2 潜伏拡散モデル

![LDMの構造](2023-06-02-14-24-39.png)
図3：**LDMの構造**
LDMの条件付けは、連結か、より一般的なクロスアテンションメカニズムで行う。3.3節参照

#### 拡散モデル

**拡散モデル**[^82]は、正規分布する変数を徐々にノイズ除去することによってデータ分布 $p(x)$ を学習するように設計された確率的モデルであり、これは長さ $T$ の固定マルコフ連鎖の逆過程を学ぶことに相当する。画像合成については、最も成功したモデル[^15] [^30] [^72]は、ノイズ除去スコアマッチ[^85]を反映する $p（x）$ の変分下限の再可重化に依拠している。これらのモデルは、入力 $x_t$（$x_t$ は入力 $x$ のノイズバージョン）のノイズ除去されたバリエーションを予測するように訓練されたノイズ除去オートエンコーダ $\epsilon_\theta(x_t,t);t=1,\cdots,T$ の等しい重み付けシーケンスとして解釈することができる。対応する目的は、$t$ を $\{1,\cdots,T\}$から均一にサンプリングして（項B）

$$L_{DM}=\mathbb{E}_{x,\epsilon～\mathcal{N}(0,1),t}[||\epsilon-\epsilon_\theta(x_t,t)||^2_2]\tag{1}$$

に単純化することができる。

#### 潜在表現の生成モデリング

$\mathcal{E}$ と $\mathcal{D}$ からなる知覚圧縮モデルの学習により、高周波数で知覚できない細部が抽象化された効率的で低次元の潜在空間を利用できるようになった。この空間は、高次元の画素空間と比較して、尤度ベースの生成モデルに適しており、（i）データの重要な意味的ビットに焦点を当て、（ii）低次元で計算効率の高い空間で訓練することができる。

高度に圧縮された離散的な潜在空間における自己回帰的な注意ベースの変換モデル[^23] [^66] [^103] に依存した以前の研究とは異なり、我々のモデルが提供する画像特有の帰納的バイアスを利用することができる。これには、主に2次元畳み込み層から基礎となるU-Netを構築する能力と、再重み付け境界を使用して知覚的に最も関連性の高いビットに目的をさらに集中させる能力が含まれ、現在では

$$L_{LDM}:=\mathbb{E}_{\mathcal{E}(x),\epsilon～\mathcal{N}(0,1),t}[||\epsilon-\epsilon_\theta(z_t,t)||^2_2]\tag{2}$$

のように読み取れる。このモデルのニューラルバックボーン $\epsilon_\theta(◦,t)$ は、時間条件付きU-Net[^71]として実現されている。  前進過程が固定であるため、$z_t$ は訓練中に $\mathcal{E}$ から効率的に得ることができ、$p(z)$ からのサンプルは $\mathcal{D}$ を1回通過するだけで画像空間に復号化されることが可能である。

### 3.3 コンディショニング・メカニズム

他のタイプの生成モデル[^56] [^83]と同様に、拡散モデルは原理的に $p(z|y)$ の形の条件付き分布をモデル化することが可能である。これは条件付きノイズ除去オートエンコーダ $\epsilon_\theta(z_t,t,y)$ で実装でき、テキスト[^68]、意味マップ[^33] [^61]、その他の画像間翻訳タスクなどの入力 $y$ を通して合成プロセスを制御する道を開く[^34]。

しかし、画像合成の文脈では、クラスラベル[^15]や入力画像の不鮮明なバリエーション[^72]以外の他のタイプの条件とDMの生成力を組み合わせることは、今のところ未開拓の研究分野である。

我々は、DMをより柔軟な条件付き画像生成器とするために、その基礎となるU-Netバックボーンを、様々な入力モダリティの注意に基づくモデルの学習に有効な交差注意メカニズム[^97]で補強する[^35] [^36]。様々なモダリティ（言語プロンプトなど）からの $y$ を前処理するために、$y$ を中間表現 $\tau_\theta(y)\in \mathbb{R}^{M\times d_\tau}$ に投影するドメイン固有エンコーダ $\tau_\theta$ を導入し、これをAttention$(Q,K,V)=$ softmax$(\frac{QK^T}{\sqrt{d}})\cdot V$ を実装したクロスアテンション層を介してU-Netの中間層へマッピングし、

$$Q=W_Q^{(i)}\cdot\varphi_i(z_t),K=W^{(i)}_K\cdot\tau_\theta(y),V=W_V^{(i)}\cdot\tau_\theta(y)$$

とする。

ここで、$\varphi_i(z_t)\in\mathbb{R}^{N×d^i_\epsilon}$ は $\epsilon_\theta$ を実装したU-Netの（平坦化された）中間表現を示し、$W^{(i)}_V\in\mathbb{R}^{d×d^i_\epsilon},W^{(i)}_Q\in\mathbb{R}^{d×d_\tau},W^{(i)}_K\in\mathbb{R}^{d×d_\tau}$ は学習型射影行列[^36] [^97]を表す。視覚的な描写については、図3を参照。

画像とコンディショニングのペアに基づき、

$$L_{LDM}:=\mathbb{E}_{\mathcal{E}(x),y,\epsilon～\mathcal{N}(0,1),t}[||\epsilon-\epsilon_\theta(z_t, t, \tau_\theta(y))||^2_2]\tag{3}$$

により条件付きLDMを学習し、$\tau_\theta$ と $\epsilon_\theta$ は式3により共同最適化される。この条件付けのメカニズムは柔軟で、$\tau_\theta$ はドメイン固有のエキスパート、例えば $y$ がテキストプロンプトの場合は（マスクされていない）変換器[^97]でパラメータ化できる（4.3.1項参照）。
