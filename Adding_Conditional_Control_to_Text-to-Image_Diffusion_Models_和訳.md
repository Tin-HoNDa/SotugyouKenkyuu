# テキストから画像へのの拡散モデルへの条件付制御の追加

Lvmin Zhang and Maneesh Agrawala
スタンフォード大学

我々は、プリトレーニングされた大規模拡散モデルを制御し、追加の入力条件に対応するためのニューラルネットワーク構造、**ControlNet** を提示する。ControlNet は、タスクに応じた条件を end-to-end で学習し、学習データセットが小さい場合（5万以下）でも安定して学習が可能である。また、ControlNet の学習は、拡散モデルのファインチューニングと同程度のスピードで行うことができ、モデルの学習は個人の端末で行うことが可能である。また、強力な計算クラスタがあれば、数百万から数十億といった膨大な量にデータにも対応できる。Stable Diffusion のような大規模な拡散モデルを ControlNet で補強することで、エッジマップ、セグメンテーションマップ、キーポイントなどの条件入力が可能になる。これにより、大規模な拡散モデルを制御する手法が充実し、関連して応用がさらに促進されることが期待される。
[https://github.com/lllyasviel/ControlNet]

## 1 はじめに

大きな text-to-image モデルでは、魅力的な画像を生産するために、ユーザーが短く記述的なプロンプトを入力しなければならない場合がある。テキストを入力し、画像を取得した後、私たちは当然、このプロンプトベースの制御は私たちのニーズを満たしているのかと疑問に思うだろう。例えば画像処理では、明確な問題設定を持つ多くの古くからのタスクを考慮すると、これらの大規模なモデルはこれらの特定のタスクの解決のために適用できるのだろうか。さまざまな問題、条件やユーザー操作に対応するためには、どのようなフレームワークを構築すればよいのか。特定のタスクにおいて、大規模モデルは数十億の画像から得られる利点や能力を維持することができるのであろうか。

これらの疑問に答えるため、さまざまな画像処理アプリケーションを調査し、3つの知見を得た。第一に、タスクに特化した領域で利用可能なデータ規模は、一般的な image-text 領域ほど大きくないことがある。特殊な問題（例えば、物体の形状・法線、ポーズ理解など）の最大データセットサイズは10万以下であることが多く、LAION-5B の $\frac{1}{5\times10^4}$ のサイズである。このため、特定の問題に対して大規模なモデルを学習させる場合、過学習を回避し、汎化能力を維持するための頑健なニューラルネットワークの学習方法が必須となる。

第二に、画像処理タスクがデータ駆動型ソリューションで処理される場合、大規模な計算クラスタが常に利用できるとは限らない。このため、大規模なモデルを特定のタスクに最適化するためには、許容できる時間とメモリ容量（例えば、PC 上）で、高速な学習方法が重要になる。そのためにはさらに、事前に学習させた重みの活用や、ファインチューニング戦略や転移学習が必要となる。

第三に、さまざまな画像処理問題は、問題定義、ユーザー制御、あるいは画像注釈の形態が多様である。これらの問題に対処する場合、画像拡散アルゴリズムは、例えば、ノイズ除去プロセスの制約、多頭の注意の活性化の編集など、「手続き的」な方法で規制することができるが、これらの手作りのルールの動作は、基本的に人間の指示によって規定されている。深度から画像、ポーズから人間などの特定のタスクを考慮すると、これらの問題は本質的に生の入力をオブジェクトレベルまたはシーンレベルの理解に解釈する必要があり、手作りの手続き的方法は実現性が低くなる。多くのタスクで学習された解を得るためには、end-to-end の学習が不可欠である。

![Canny エッジマップを用いた Stable Diffusion の制御](2023-05-22-14-31-44.png)
図1：**Canny エッジマップを用いた Stable Diffusion の制御**
Canny エッジマップを入力し、右の画像を生成する際には、ソース画像は使用しない。出力は、デフォルトのプロンプト「a high-quality, detailed, and professional image」で実現されている。このプロンプトは、画像の内容やオブジェクト名について何も言及しないデフォルトのプロンプトとして、本稿で使用されている。本論文の図の多くは高解像度の画像であり、拡大すると最も見やすくなる。

本論文では、大規模な画像拡散モデル（Stable Diffusion など）を制御し、タスク固有の入力条件を学習させる end-to-end のニューラルネットワーク構造である ControlNet を紹介する。ControlNet は、大規模拡散モデルの重みを「訓練されたコピー」と「ロックされたコピー」にクローン化する。ロックされたコピーは数十億枚の画像から学習したネットワーク能力を保持し、訓練可能なコピーはタスク固有のデータセットで訓練して条件制御を学習させる。訓練可能なニューラルネットワークブロックとロックされたニューラルネットワークブロックは、「ゼロコンボリューション」と呼ばれる独自のタイプのコンボリューション層で接続されており、コンボリューションの重みはゼロから最適化されたパラメータまで学習しながら徐々に大きくなっていく。生産に適した重みが保持されるため、さまざまなスケールのデータセットで頑丈な学習が可能である。ゼロコンボリューションは深層特徴に新たなノイズを加えないため、ゼロから新しいレイヤーをトレーニングするのに比べ、拡散モデルをファインチューニングするのと同じくらい速く訓練できる。

Canny エッジ、Hough ライン、ユーザーの走り書き、人間のキーポイント、セグメンテーションマップ、形状法線、深度など、様時ざまな条件ので＾タセットを用いて、複数の ControlNet を訓練している。また、ControlNet を小規模データセット（サンプル数5万以下、千以下）と大規模データセット（サンプル数数百万）の両方で実験した。また、深度画像のようないくつかのタスクでは、PC（Nvidia RTX 3090TI 1台）でControlNetを訓練すると、TB のGPU メモリと数千 GPU 時間を持つ大規模計算クラスターで訓練した商用モデルと同等の結果が得られることを示した。

## 2 関連した研究

### 2.1 HyperNetwork and Neural Network Structure

### 2.2 Diffusion Probabilistic Model

### 2.3 Text-to-Image Diffusion

### 2.4 Personalization, Customization, and Control of Pretrained Diffusion Model

### 2.5 Image-to-Image Translation

## 3 Method

### 3.1 ControlNet

### 3.2 ControlNet in Image Diffusion Model

### 3.3 Training

### 3.4 Improved Training

### 3.5 Implementation

## 4 Experiment

### 4.1 Experimental Settings

### 4.2 Qualitative Results

### 4.3 Ablation Study

### 4.4 Comparison to previous methods

### 4.5 Comparison of pre-trained medels

### 4.6 More Applications

## 5 Limitation

## Appendix

## References
