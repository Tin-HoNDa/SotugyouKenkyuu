{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May  9 10:44:47 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 517.40       Driver Version: 517.40       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   36C    P8    11W /  N/A |   2471MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     12208    C+G   ...n64\\EpicGamesLauncher.exe    N/A      |\n",
      "|    0   N/A  N/A     34088      C   ...thon\\Python310\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\honda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\honda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 0.13.1 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\n",
      "torchtext 0.14.1 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\n",
      "torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\honda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\honda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\honda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\honda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xformers 0.0.19 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -q --user diffusers==0.14.0 transformers xformers git+https://github.com/huggingface/accelerate.git\n",
    "!python -m pip install -q opencv-contrib-python\n",
    "!python -m pip install -q controlnet_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StableDiffusionControlNetPipeline' from 'diffusers' (c:\\Users\\honda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\diffusers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\授業\\5年_卒業研究\\ControlNet.ipynb セル 3\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%E6%8E%88%E6%A5%AD/5%E5%B9%B4_%E5%8D%92%E6%A5%AD%E7%A0%94%E7%A9%B6/ControlNet.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# import\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/%E6%8E%88%E6%A5%AD/5%E5%B9%B4_%E5%8D%92%E6%A5%AD%E7%A0%94%E7%A9%B6/ControlNet.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiffusers\u001b[39;00m \u001b[39mimport\u001b[39;00m StableDiffusionControlNetPipeline\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%E6%8E%88%E6%A5%AD/5%E5%B9%B4_%E5%8D%92%E6%A5%AD%E7%A0%94%E7%A9%B6/ControlNet.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiffusers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_image\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%E6%8E%88%E6%A5%AD/5%E5%B9%B4_%E5%8D%92%E6%A5%AD%E7%A0%94%E7%A9%B6/ControlNet.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m input_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mramen.JPG\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'StableDiffusionControlNetPipeline' from 'diffusers' (c:\\Users\\honda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\diffusers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from diffusers import StableDiffusionControlNetPipeline\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "input_path = \"ramen.JPG\"\n",
    "\n",
    "# 画像読み込み\n",
    "image = load_image(input_path)\n",
    "image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "image = np.array(image)\n",
    "\n",
    "low_threshold = 100\n",
    "high_threshold = 200\n",
    "\n",
    "image = cv2.Canny(image, low_threshold, high_threshold)\n",
    "image = image[:, :, None]\n",
    "image = np.concatenate([image, image, image], axis=2)\n",
    "canny_image = Image.fromarray(image)\n",
    "canny_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
    "from diffusers import UniPCMultistepScheduler\n",
    "\n",
    "# Canny特徴用のControlNetモデルとrunwaylml/stable-diffusion-v1-5をロード\n",
    "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\", torch_dtype=torch.float16)\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\", controlnet=controlnet, torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Stable DiffusionのデフォルトのPNDMSchedulerを使う代わりに、UniPCMultistepSchedulerという現在最も高速な拡散モデルスケジューラの1つを使用\n",
    "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "# パイプラインを直接GPUにロードする代わりに、enable_model_cpu_offload関数でCPUオフロードを有効にする\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "# FlashAttention/xformersのアテンションレイヤーアクセラレーションを有効にする\n",
    "pipe.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows * cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
    "    grid_w, grid_h = grid.size\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
    "    return grid\n",
    "\n",
    "# prompt = \", best quality, extremely detailed\"\n",
    "# prompt = [t + prompt for t in [\"spring\", \"summer\", \"autumn\", \"winter\"]]\n",
    "prompt = [\"pasta, best quality, extremely detailed\"]\n",
    "generator = [torch.Generator(device=\"cpu\").manual_seed(2) for i in range(len(prompt))]\n",
    "\n",
    "output = pipe(\n",
    "    prompt,\n",
    "    canny_image,\n",
    "    negative_prompt=[\"monochrome, lowres, bad anatomy, worst quality, low quality\"] * len(prompt),\n",
    "    generator=generator,\n",
    "    num_inference_steps=20,\n",
    ")\n",
    "\n",
    "output.images[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
